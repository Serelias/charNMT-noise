# charNMT-noise
Scripts and noise data for Belinkov &amp; Bisk [Synthetic and Natural Noise Both Break Neural Machine Translation](https://arxiv.org/abs/1711.02173) ICLR 2018 


## MT Data
The experiments reported in the paper are conducted on the TED talks corpus prepared for [IWSLT 2016](http://workshop2016.iwslt.org), which is available on the [WIT<sup>3</sup> website](https://wit3.fbk.eu/mt.php?release=2016-01). 

## Pretrained Models
Nematus: http://data.statmt.org/rsennrich/wmt16_systems/

char2char: https://github.com/nyu-dl/dl4mt-c2c

## Sources of Natural Noise 
French: 
  > Aurlien Max and Guillaume Wisniewski. _Mining Naturally-occurring Corrections and Paraphrases from Wikipedias 
  > Revision History_ LREC 2010 [corpus](https://wicopaco.limsi.fr)

German:
  > Katrin Wisniewski et al. _MERLIN: an online trilingual learner corpus empirically grounding the European Reference Levels 
  > in authentic learner data_ 2013 [corpus1](https://www.ukp.tu-darmstadt.de/data/spelling-correction/rwse-datasets) [corpus2](https://www.ukp.tu-darmstadt.de/data/spelling-correction/spelling-difficulty-prediction/)


Czech:  
  > Karel Sebesta et al. _CzeSL grammatical error correction dataset (CZeSL-GEC)_ Tech Report 
  > LINDAT/CLARIN digital library at the Institute of Formal and Applied Linguistics, Charles University 2017 [corpus](https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-2143)
